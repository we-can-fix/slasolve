# ============================================================================
# 性能優化規則 (Performance Optimization Rules)
# ============================================================================

version: "1.0.0"
category: "performance"
priority: "high"

rules:
  # N+1 查詢優化
  - id: "PERF-001"
    name: "n-plus-one-query"
    description: "檢測並修復 N+1 查詢問題"
    severity: "HIGH"
    enabled: true
    
    patterns:
      - type: "loop_with_query"
        example: |
          for item in items:
              related = db.query(Related).filter(Related.id == item.id).first()
    
    fix_strategy:
      type: "batch_query"
      template: "performance-batch-query"
      action: |
        # 使用批量查詢
        original:
          for item in items:
              related = db.query(Related).filter(Related.id == item.id).first()
        
        replacement:
          item_ids = [item.id for item in items]
          related_map = {r.id: r for r in db.query(Related).filter(Related.id.in_(item_ids)).all()}
          for item in items:
              related = related_map.get(item.id)
    
    expected_improvement: "80-95% 查詢時間減少"
    
    verification:
      - run_tests: true
      - performance_benchmark: true
      - query_count_check: true

  # 低效循環優化
  - id: "PERF-002"
    name: "inefficient-loop"
    description: "優化嵌套循環和低效迭代"
    severity: "MEDIUM"
    enabled: true
    
    patterns:
      - type: "nested_loop"
        complexity_threshold: 2
      - type: "linear_search_in_loop"
    
    fix_strategy:
      type: "algorithm_optimization"
      template: "performance-loop-optimize"
      action: |
        # 使用哈希表或集合優化
        original:
          for item in items:
              for other in others:
                  if item.id == other.id:
                      process(item, other)
        
        replacement:
          others_map = {o.id: o for o in others}
          for item in items:
              if item.id in others_map:
                  process(item, others_map[item.id])
    
    expected_improvement: "O(n²) → O(n)"
    
    verification:
      - run_tests: true
      - performance_benchmark: true

  # 記憶體優化
  - id: "PERF-003"
    name: "memory-optimization"
    description: "優化記憶體使用"
    severity: "MEDIUM"
    enabled: true
    
    patterns:
      - type: "large_list_comprehension"
      - type: "unnecessary_copy"
      - type: "memory_leak"
    
    fix_strategy:
      type: "memory_efficient"
      template: "performance-memory-optimize"
      action: |
        # 使用生成器或迭代器
        original:
          results = [process(item) for item in large_dataset]
        
        replacement:
          results = (process(item) for item in large_dataset)
          # 或使用分批處理
          for batch in chunks(large_dataset, 1000):
              process_batch(batch)
    
    expected_improvement: "記憶體使用減少 50-90%"
    
    verification:
      - run_tests: true
      - memory_profiling: true

  # 緩存策略
  - id: "PERF-004"
    name: "missing-cache"
    description: "添加適當的緩存"
    severity: "MEDIUM"
    enabled: true
    
    patterns:
      - type: "repeated_computation"
      - type: "expensive_function_call"
    
    fix_strategy:
      type: "add_caching"
      template: "performance-cache"
      action: |
        # 添加 LRU 緩存
        original:
          def expensive_function(param):
              # 昂貴的計算
              return result
        
        replacement:
          from functools import lru_cache
          
          @lru_cache(maxsize=128)
          def expensive_function(param):
              # 昂貴的計算
              return result
    
    expected_improvement: "計算時間減少 70-99%"
    
    verification:
      - run_tests: true
      - performance_benchmark: true
      - cache_hit_rate_check: true

  # 數據庫查詢優化
  - id: "PERF-005"
    name: "inefficient-query"
    description: "優化數據庫查詢"
    severity: "HIGH"
    enabled: true
    
    patterns:
      - type: "missing_index"
      - type: "select_all"
      - type: "missing_join"
    
    fix_strategy:
      type: "query_optimization"
      template: "performance-query-optimize"
      action: |
        # 優化查詢
        original:
          results = db.query(Model).all()
          filtered = [r for r in results if r.status == 'active']
        
        replacement:
          results = db.query(Model).filter(Model.status == 'active').all()
    
    expected_improvement: "查詢時間減少 60-95%"
    
    verification:
      - run_tests: true
      - explain_analyze: true
      - performance_benchmark: true

  # 並發優化
  - id: "PERF-006"
    name: "parallelization-opportunity"
    description: "識別並實現並行化機會"
    severity: "MEDIUM"
    enabled: true
    
    patterns:
      - type: "independent_operations"
      - type: "io_bound_loop"
    
    fix_strategy:
      type: "add_parallelization"
      template: "performance-parallel"
      action: |
        # 使用並行處理
        original:
          results = [fetch_data(url) for url in urls]
        
        replacement:
          from concurrent.futures import ThreadPoolExecutor
          
          with ThreadPoolExecutor(max_workers=10) as executor:
              results = list(executor.map(fetch_data, urls))
    
    expected_improvement: "執行時間減少 50-90%"
    
    verification:
      - run_tests: true
      - performance_benchmark: true
      - thread_safety_check: true

# ============================================================================
# 性能基準
# ============================================================================

performance_benchmarks:
  response_time:
    p50: 100  # ms
    p95: 200  # ms
    p99: 500  # ms
  
  throughput:
    min: 1000  # requests/sec
    target: 5000  # requests/sec
  
  memory:
    max_heap: 512  # MB
    max_rss: 1024  # MB
  
  cpu:
    max_usage: 0.8  # 80%
    target_usage: 0.5  # 50%

# ============================================================================
# 修復配置
# ============================================================================

fix_config:
  auto_apply: false
  require_review: true
  create_backup: true
  run_benchmarks: true
  generate_report: true
  
  benchmark_requirements:
    min_improvement: 0.2  # 20% improvement
    max_regression: 0.05  # 5% regression acceptable
    
  rollback_conditions:
    - test_failure: true
    - performance_regression: true
    - memory_increase: 0.2  # 20% increase
